{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f67284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-May-24 17:30:07 - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from ntscraper import Nitter\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import re\n",
    "import neattext.functions as nfx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17542b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 71/77 [03:20<00:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-May-24 17:33:43 - Certificate did not match expected hostname: nt.ggtyler.dev. Certificate: {'subject': ((('commonName', '4g.ggtyler.dev'),),), 'issuer': ((('countryName', 'US'),), (('organizationName', \"Let's Encrypt\"),), (('commonName', 'R3'),)), 'version': 3, 'serialNumber': '03A4459CE6DA31CFF555DB78FF3F35BFEA88', 'notBefore': 'May 14 10:55:44 2024 GMT', 'notAfter': 'Aug 12 10:55:43 2024 GMT', 'subjectAltName': (('DNS', '4g.ggtyler.dev'),), 'OCSP': ('http://r3.o.lencr.org',), 'caIssuers': ('http://r3.i.lencr.org/',)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 73/77 [03:24<00:06,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-May-24 17:33:44 - Certificate did not match expected hostname: nitter.uni-sonia.com. Certificate: {'subject': ((('commonName', '*.xserver.jp'),),), 'issuer': ((('countryName', 'JP'),), (('organizationName', 'CloudSecure Corporation'),), (('commonName', 'CloudSecure RSA Domain Validation Secure Server CA 2'),)), 'version': 3, 'serialNumber': 'ACA67AD2030638EE2DCE8E845B8299A6', 'notBefore': 'Mar 11 00:00:00 2024 GMT', 'notAfter': 'Apr 11 23:59:59 2025 GMT', 'subjectAltName': (('DNS', '*.xserver.jp'), ('DNS', 'xserver.jp')), 'OCSP': ('http://ocsp.sectigo.com',), 'caIssuers': ('http://crt.sectigo.com/CloudSecureRSADomainValidationSecureServerCA2.crt',)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 76/77 [03:29<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-May-24 17:33:49 - Certificate did not match expected hostname: nitter.tinfoil-hat.net. Certificate: {'subject': ((('commonName', 'jelly.tinfoil-hat.de'),),), 'issuer': ((('countryName', 'US'),), (('organizationName', \"Let's Encrypt\"),), (('commonName', 'R3'),)), 'version': 3, 'serialNumber': '03F338CE809E122DC2875C50A27A840DD7A4', 'notBefore': 'Mar 15 22:40:16 2024 GMT', 'notAfter': 'Jun 13 22:40:15 2024 GMT', 'subjectAltName': (('DNS', 'jelly.tinfoil-hat.de'),), 'OCSP': ('http://r3.o.lencr.org',), 'caIssuers': ('http://r3.i.lencr.org/',)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [03:30<00:00,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45fa833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(name,modes,no):\n",
    "    tweets = scraper.get_tweets(name,mode = modes, number = no)    \n",
    "    final_tweets = []\n",
    "    for tweet in tweets['tweets']:\n",
    "        data = [tweet['link'],tweet['text'],tweet['date'], tweet['stats']['likes'],tweet['stats']['comments']]\n",
    "        final_tweets.append(data)\n",
    "    data = pd.DataFrame(final_tweets, columns = ['link','Tweets','Date','Likes','Count(Comments)'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf56198-ba27-417a-ad12-7bd862254e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input(\"Enter the username: \")\n",
    "modes = input(\"enter the mode as 'term', 'hashtag' or 'user':\")\n",
    "no = int(input(\"Enter the number of tweets to analyze: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e851a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_tweets('AdityaBirlaGrp','user',200) # Use 'term', 'hashtag', or 'user'.\n",
    "# DrSJaishankar\n",
    "# elon\n",
    "data = get_tweets(name,modes,no) # Use 'term', 'hashtag', or 'user'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2955930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc39e9e-d05e-4951-b05b-3047bb0e27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "from langdetect import detect \n",
    "\n",
    "# Create a function to translate the tweets\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        detected_language = detect(text)\n",
    "        translator = Translator(to_lang=\"en\", from_lang=detected_language)\n",
    "        translated_text = translator.translate(text)\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during translation:\", e)\n",
    "        return text\n",
    "\n",
    "\n",
    "data['Tweets_en'] = data['Tweets'].apply(translate_text)\n",
    "data['Tweets_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e8db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    " text = re.sub('@[A-Za-z0‚Äì9]+', '', text) #Removing @mentions\n",
    " text = re.sub('#', '', text) # Removing '#' hash tag\n",
    " text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
    " text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
    " return text\n",
    "\n",
    "\n",
    "# Clean the tweets\n",
    "data['Tweets_en'] = data['Tweets_en'].apply(cleanTxt)\n",
    "data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_stopwords)\n",
    "data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_punctuations)\n",
    "\n",
    "# Show the cleaned tweets\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e6b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "   return  TextBlob(text).sentiment.polarity\n",
    "\n",
    "\n",
    "# Create two new columns 'Subjectivity' & 'Polarity'\n",
    "data['Subjectivity'] = data['Tweets_en'].apply(getSubjectivity)\n",
    "data['Polarity'] = data['Tweets_en'].apply(getPolarity)\n",
    "\n",
    "# Show the new dataframe with columns 'Subjectivity' & 'Polarity'\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa518d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # word cloud visualization\n",
    "\n",
    "# # Remove extra whitespace from the allWords string\n",
    "# allWords = ' '.join([twts for twts in data['Tweets']]).strip()\n",
    "# mywordCloud = WordCloud( width=500, height=300, max_font_size=110).generate(allWords)\n",
    "# plt.figure(figsize=(8,3))\n",
    "# plt.imshow(mywordCloud, interpolation=\"bilinear\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    allWords = ' '.join([twts for twts in text]).strip()\n",
    "    mywordCloud = WordCloud(width=500, height=300, max_font_size=110).generate(allWords)\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.imshow(mywordCloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "generate_wordcloud(data['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute negative (-1), neutral (0) and positive (+1) analysis\n",
    "def getAnalysis(score):\n",
    "  if score < 2:\n",
    "    return 'Negative'\n",
    "  elif score == 0:\n",
    "    return 'Neutral'\n",
    "  else:\n",
    "    return 'Positive'\n",
    "\n",
    "def getEmoji(score):\n",
    "  if score < 0:\n",
    "    return 'üòî'\n",
    "  elif score == 0:\n",
    "    return 'üòê'\n",
    "  else:\n",
    "    return 'üôÇ'\n",
    "      \n",
    "data['Analysis'] = data['Polarity'].apply(getEmoji)\n",
    "# Show the dataframe\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2f52e-6a76-4bc9-b132-04833fadbe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "counts = data['Analysis'].value_counts()\n",
    "fig = px.bar(x=counts.index, y=counts.values)\n",
    "fig.update_layout(title='Sentiment Analysis',\n",
    "                  xaxis_title='Sentiment',\n",
    "                  yaxis_title='Counts')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5282c-a342-49a9-a02c-b834aa915693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def generate_bar_chart(data):\n",
    "    counts = data['Analysis'].value_counts()\n",
    "    values = counts.index\n",
    "\n",
    "    fig = go.Figure(data=[go.Bar(x=values, y=counts.values, marker=dict(color=['blue', 'green', 'red', 'purple', 'yellow']), name=values[0])])\n",
    "    fig.update_layout(title='Sentiment Analysis', xaxis_title='Sentiment', yaxis_title='Counts')\n",
    "    fig.show()\n",
    "    \n",
    "generate_bar_chart(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f9c4e-c306-4ad1-b601-a9fbad187ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# def predict_with_model(df):\n",
    "#     # Load the model\n",
    "#     model = joblib.load('clf.pkl')\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = model.predict(df)\n",
    "    \n",
    "#     # Define a mapping between numeric labels and sentiment categories\n",
    "#     sentiment_mapping = {\n",
    "#         0: 'Negative',\n",
    "#         1: 'Neutral',\n",
    "#         2: 'Positive'\n",
    "#     }\n",
    "    \n",
    "#     # Convert numeric labels to sentiment categories\n",
    "#     predicted_sentiments = [sentiment_mapping[label] for label in predictions]\n",
    "    \n",
    "#     return predicted_sentiments\n",
    "def predict_with_model(text_list):\n",
    "    # Load the model\n",
    "    model = joblib.load('clf.pkl')\n",
    "    # Make predictions\n",
    "    predictions = model.predict(text_list)\n",
    "    # Define a mapping between numeric labels and sentiment categories\n",
    "    sentiment_mapping = {\n",
    "        0: 'Negative',\n",
    "        1: 'Neutral',\n",
    "        2: 'Positive'\n",
    "    }\n",
    "    # Convert numeric labels to sentiment categories for each prediction\n",
    "    predicted_sentiments = [sentiment_mapping[label] for label in predictions]\n",
    "    return predicted_sentiments\n",
    "\n",
    "data['predictions'] = predict_with_model(data['Tweets_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbf19c-a90f-4c7e-847e-c56661e7ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "counts = data['predictions'].value_counts()\n",
    "fig = px.bar(x=counts.index, y=counts.values)\n",
    "fig.update_layout(title='Sentiment Analysis',\n",
    "                  xaxis_title='Sentiment',\n",
    "                  yaxis_title='Counts')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4235b-ef5c-4e98-bb95-fa0fc23f3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    # Concatenate all words in the text data\n",
    "    allWords = ' '.join([twts for twts in text]).strip()\n",
    "    \n",
    "    # Create a WordCloud object with appropriate font for multi-language support\n",
    "    # You can specify a font file that supports multiple languages, such as Arial Unicode MS\n",
    "    mywordCloud = WordCloud(width=500, height=300, max_font_size=110, font_path='arial.ttf').generate(allWords)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(mywordCloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.show()\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "# from langdetect import detect\n",
    "# import re\n",
    "\n",
    "# def generate_wordcloud(text):\n",
    "#     # Concatenate all words in the text data\n",
    "#     allWords = ' '.join(text)\n",
    "\n",
    "#     # Filter out non-alphanumeric characters and extra spaces\n",
    "#     allWords = re.sub(r'[^\\w\\s]', '', allWords)\n",
    "#     allWords = re.sub(r'\\s+', ' ', allWords)\n",
    "\n",
    "#     # Detect the language of each word and create a WordCloud for each language\n",
    "#     wordclouds = {}\n",
    "#     for word in allWords.split():\n",
    "#         try:\n",
    "#             lang = detect(word)\n",
    "#             if lang not in wordclouds:\n",
    "#                 wordclouds[lang] = ''\n",
    "#             wordclouds[lang] += word + ' '\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     # Generate WordCloud for each language\n",
    "#     for lang, words in wordclouds.items():\n",
    "#         mywordCloud = WordCloud(width=500, height=300, max_font_size=110, font_path='arial.ttf').generate(words)\n",
    "\n",
    "#         # Display the word cloud\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.imshow(mywordCloud, interpolation='bilinear')\n",
    "#         plt.title(f'Word Cloud for {lang}')\n",
    "#         plt.axis('off')  # Hide the axes\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = [\"Hello\", \"Bonjour\", \"Hola\", \"Ciao\", \"–ü—Ä–∏–≤–µ—Ç\", \"‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•ã ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§â‡§∏‡§ï‡•Ä ‡§Ö‡§≠‡§ø‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•Ä\"]\n",
    "generate_wordcloud(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f94902",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Tweets_en']=final_df['Tweets_en'].astype(str)\n",
    "final_df['Tweets_en']=final_df['Tweets_en'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a819c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "  y=[]\n",
    "  for i in text.split():\n",
    "    y.append(ps.stem(i))\n",
    "  return \" \".join(y) #returns string after stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d782b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Tweets_en']= final_df['Tweets_en'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_model = LabelEncoder()\n",
    "final_df['Label'] = le_model.fit_transform(final_df['Analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9eafe-ab0f-48bc-924c-8b1241944aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the pickle model\n",
    "with open('clf.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827dd3b7-4b19-4017-9d5a-3acd2e2f17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(final_df['Tweets_en'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0613f-da6a-4738-8126-7183f1b9788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make predictions on the Tweets_en column\n",
    "predictions = model.predict(final_df['Tweets_en'])\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions)\n",
    "\n",
    "# Add the predicted labels to the final_df dataframe\n",
    "final_df['Predicted_Label'] = classes[predicted_labels]\n",
    "\n",
    "# Print the first 5 rows of the final_df dataframe\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39453c1d-cc9a-4f6e-9198-70e243538da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "print(f\"True Label: {final_df['Analysis'][0]}\")\n",
    "print(f'Predict Label: {classes[test[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fc3fd-dca7-4184-bd00-f866a73a6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "data["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063e04e-4c08-4c6c-b06c-2b9ff816c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predicted_Analysis']=classes[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae43147-68ff-4ee5-b49f-2a4dfc3f9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Tweets','Analysis']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5152c21-f385-4c9a-bd1d-b5e19ac1dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Tweets(name,modes,no):\n",
    "    data = get_tweets(name,modes,no)\n",
    "    \n",
    "    data['Tweets_en'] = data['Tweets'].apply(translate_text)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(cleanTxt)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_stopwords)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_punctuations)\n",
    "    \n",
    "    data['Subjectivity'] = data['Tweets_en'].apply(getSubjectivity)\n",
    "    data['Polarity'] = data['Tweets_en'].apply(getPolarity)\n",
    "    data['Analysis'] = data['Polarity'].apply(getAnalysis)\n",
    "\n",
    "    print(data)\n",
    "    print(generate_wordcloud(data['Tweets']))\n",
    "    print(generate_bar_chart(data))\n",
    "    print(data[['Tweets','Analysis']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c635cc2-bdbe-41c3-8ae1-2ebc2eb823f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_Tweets('opdaiIy','user',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbf5ee-ba3b-419b-a1e3-ea0c4a3f6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a00e41-b4aa-4467-b639-9a91884444e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Tweets1(data):\n",
    "    data['Tweets_en'] = data['Tweets'].apply(translate_text)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(cleanTxt)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_stopwords)\n",
    "    data['Tweets_en'] = data['Tweets_en'].apply(nfx.remove_punctuations)\n",
    "    \n",
    "    data['Subjectivity'] = data['Tweets_en'].apply(getSubjectivity)\n",
    "    data['Polarity'] = data['Tweets_en'].apply(getPolarity)\n",
    "    data['Analysis'] = data['Polarity'].apply(getAnalysis)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64944af5-21ea-496b-b7c2-24e716896bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Analyze_Tweets1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad891d7-4050-472d-9a46-31743cc391b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7f42e-1b1d-4845-933d-aba207d27a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
